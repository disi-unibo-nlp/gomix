For now, I'm just testing the embedding of the proteins from the CAFA3 challenge, and the GO term classification with them as input, using a FC network.

## Results

**With esm2_t33_650M_UR50D embeddings:** about 20% F1-score at t=0.5 (64% precision and 11% recall).

**With esm2_t36_3B_UR50D embeddings, same model size:** about 30% F1-score at t=0.5 (65% precision and 20% recall).

**With esm2_t36_3B_UR50D embeddings, larger model + dropout:** about 35% F1-score at=0.5 (66% precision and 22% recall). F_max approximates 45%.

### Current status

I have to try using the embeddings generated by larger versions of the ESM2 protein embedding model.
